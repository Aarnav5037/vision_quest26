{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14465713,"sourceType":"datasetVersion","datasetId":9239696},{"sourceId":717797,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":545752,"modelId":558766}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import models, datasets, transforms\nfrom torch.utils.data import DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-12T18:30:36.968371Z","iopub.execute_input":"2026-01-12T18:30:36.969099Z","iopub.status.idle":"2026-01-12T18:30:44.052575Z","shell.execute_reply.started":"2026-01-12T18:30:36.969057Z","shell.execute_reply":"2026-01-12T18:30:44.051826Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1  # output channels multiplier\n\n    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n        super().__init__()\n        # First conv\n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n                               stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        # Second conv\n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n                               stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        # Downsample for residual if needed\n        self.downsample = downsample\n        self.relu = nn.ReLU(inplace=True)\n\n    def forward(self, x):\n        identity = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            identity = self.downsample(x)\n\n        out += identity\n        out = self.relu(out)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T20:57:22.399674Z","iopub.execute_input":"2026-01-12T20:57:22.399986Z","iopub.status.idle":"2026-01-12T20:57:22.407297Z","shell.execute_reply.started":"2026-01-12T20:57:22.399954Z","shell.execute_reply":"2026-01-12T20:57:22.406527Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"class ResNet18(nn.Module):\n    def __init__(self, num_classes=1000):\n        super().__init__()\n        self.in_channels = 64\n\n        # Initial convolution and maxpool\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Residual layers\n        self.layer1 = self._make_layer(64, 2)   # 2 blocks\n        self.layer2 = self._make_layer(128, 2, stride=2)\n        self.layer3 = self._make_layer(256, 2, stride=2)\n        self.layer4 = self._make_layer(512, 2, stride=2)\n\n        # Average pooling and FC\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512 * BasicBlock.expansion, num_classes)\n\n    def _make_layer(self, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels * BasicBlock.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels * BasicBlock.expansion,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels * BasicBlock.expansion),\n            )\n\n        layers = []\n        layers.append(BasicBlock(self.in_channels, out_channels, stride, downsample))\n        self.in_channels = out_channels * BasicBlock.expansion\n        for _ in range(1, blocks):\n            layers.append(BasicBlock(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        # Initial\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        # Residual layers\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        # Pool and classify\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T20:27:32.429552Z","iopub.execute_input":"2026-01-12T20:27:32.429889Z","iopub.status.idle":"2026-01-12T20:27:32.440517Z","shell.execute_reply.started":"2026-01-12T20:27:32.429860Z","shell.execute_reply":"2026-01-12T20:27:32.439653Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"class ResNet14(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.in_channels = 64\n\n        # Stem\n        self.conv1 = nn.Conv2d(\n            3, 64, kernel_size=7, stride=2, padding=3, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Residual layers (ResNet-14)\n        self.layer1 = self._make_layer(64, blocks=1)\n        self.layer2 = self._make_layer(128, blocks=1, stride=2)\n        self.layer3 = self._make_layer(256, blocks=2, stride=2)\n        self.layer4 = self._make_layer(512, blocks=2, stride=2)\n\n        # Head\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, num_classes)\n\n        self._init_weights()\n\n    def _make_layer(self, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels),\n            )\n\n        layers = []\n        layers.append(\n            BasicBlock(self.in_channels, out_channels, stride, downsample)\n        )\n        self.in_channels = out_channels\n\n        for _ in range(1, blocks):\n            layers.append(BasicBlock(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T18:31:15.494933Z","iopub.execute_input":"2026-01-12T18:31:15.495568Z","iopub.status.idle":"2026-01-12T18:31:15.505688Z","shell.execute_reply.started":"2026-01-12T18:31:15.495538Z","shell.execute_reply":"2026-01-12T18:31:15.504738Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class ResNet10(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.in_channels = 64\n\n        # Stem\n        self.conv1 = nn.Conv2d(\n            3, 64, kernel_size=7, stride=2, padding=3, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n\n        # Residual layers (ResNet-10)\n        self.layer1 = self._make_layer(64, blocks=1)\n        self.layer2 = self._make_layer(128, blocks=1, stride=2)\n        self.layer3 = self._make_layer(256, blocks=1, stride=2)\n        self.layer4 = self._make_layer(512, blocks=1, stride=2)\n\n        # Head\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, num_classes)\n\n        self._init_weights()\n\n    def _make_layer(self, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels),\n            )\n\n        layers = []\n        layers.append(\n            BasicBlock(self.in_channels, out_channels, stride, downsample)\n        )\n        self.in_channels = out_channels\n\n        for _ in range(1, blocks):\n            layers.append(BasicBlock(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:29:43.429069Z","iopub.execute_input":"2026-01-12T21:29:43.429378Z","iopub.status.idle":"2026-01-12T21:29:43.440146Z","shell.execute_reply.started":"2026-01-12T21:29:43.429352Z","shell.execute_reply":"2026-01-12T21:29:43.439366Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"class ResNet34(nn.Module):\n    def __init__(self, num_classes=7):\n        super().__init__()\n        self.in_channels = 64\n\n        # Stem\n        self.conv1 = nn.Conv2d(\n            3, 64, kernel_size=7, stride=2, padding=3, bias=False\n        )\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(3, 2, 1)\n\n        # Residual layers (ResNet-34)\n        self.layer1 = self._make_layer(64, blocks=3)\n        self.layer2 = self._make_layer(128, blocks=4, stride=2)\n        self.layer3 = self._make_layer(256, blocks=6, stride=2)\n        self.layer4 = self._make_layer(512, blocks=3, stride=2)\n\n        # Head\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        self.fc = nn.Linear(512, num_classes)\n\n        self._init_weights()\n\n    def _make_layer(self, out_channels, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_channels != out_channels:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_channels, out_channels,\n                          kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(out_channels),\n            )\n\n        layers = []\n        layers.append(\n            BasicBlock(self.in_channels, out_channels, stride, downsample)\n        )\n        self.in_channels = out_channels\n\n        for _ in range(1, blocks):\n            layers.append(BasicBlock(self.in_channels, out_channels))\n\n        return nn.Sequential(*layers)\n\n    def _init_weights(self):\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n            elif isinstance(m, nn.Linear):\n                nn.init.normal_(m.weight, 0, 0.01)\n                nn.init.constant_(m.bias, 0)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T19:33:11.786358Z","iopub.execute_input":"2026-01-12T19:33:11.786861Z","iopub.status.idle":"2026-01-12T19:33:11.797496Z","shell.execute_reply.started":"2026-01-12T19:33:11.786833Z","shell.execute_reply":"2026-01-12T19:33:11.796677Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nnum_classes = 7\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = ResNet10(num_classes=num_classes)\nmodel = model.to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T20:57:42.760320Z","iopub.execute_input":"2026-01-12T20:57:42.760646Z","iopub.status.idle":"2026-01-12T20:57:42.843640Z","shell.execute_reply.started":"2026-01-12T20:57:42.760615Z","shell.execute_reply":"2026-01-12T20:57:42.842678Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"from torchvision import transforms\n\ntrain_transform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n\n    # Mild geometric invariance\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=10),\n\n    # Preserve facial structure\n    transforms.Resize((224, 224)),\n\n    transforms.ToTensor(),\n\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ),\n])\ntest_transform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=3),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    ),\n])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T20:57:44.852850Z","iopub.execute_input":"2026-01-12T20:57:44.853205Z","iopub.status.idle":"2026-01-12T20:57:44.859755Z","shell.execute_reply.started":"2026-01-12T20:57:44.853173Z","shell.execute_reply":"2026-01-12T20:57:44.858663Z"}},"outputs":[],"execution_count":60},{"cell_type":"code","source":"train_dataset = datasets.ImageFolder(\"/kaggle/input/visionquest/train\", transform=train_transform)\ntest_dataset   = datasets.ImageFolder(\"/kaggle/input/visionquest/test\", transform=test_transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\ntest_loader   = DataLoader(test_dataset, batch_size=128, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T20:57:46.806430Z","iopub.execute_input":"2026-01-12T20:57:46.806748Z","iopub.status.idle":"2026-01-12T20:58:06.495666Z","shell.execute_reply.started":"2026-01-12T20:57:46.806717Z","shell.execute_reply":"2026-01-12T20:58:06.494700Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom collections import Counter\n\n# Extract labels from dataset\ntargets = [label for _, label in train_dataset.samples]\n\nclass_counts = Counter(targets)\nnum_classes = len(class_counts)\n\n# Inverse frequency weighting\nclass_weights = np.zeros(num_classes, dtype=np.float32)\nfor cls, count in class_counts.items():\n    class_weights[cls] = 1.0 / count\n\n# Normalize (important for stability)\nclass_weights = class_weights / class_weights.sum() * num_classes\n\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T20:58:06.496989Z","iopub.execute_input":"2026-01-12T20:58:06.497345Z","iopub.status.idle":"2026-01-12T20:58:06.508445Z","shell.execute_reply.started":"2026-01-12T20:58:06.497304Z","shell.execute_reply":"2026-01-12T20:58:06.507545Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss(\n    weight=class_weights,\n    label_smoothing=0.1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T20:58:44.297768Z","iopub.execute_input":"2026-01-12T20:58:44.298222Z","iopub.status.idle":"2026-01-12T20:58:44.302880Z","shell.execute_reply.started":"2026-01-12T20:58:44.298191Z","shell.execute_reply":"2026-01-12T20:58:44.301886Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=3e-4,\n    weight_decay=1e-4\n)\n\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer,\n    mode='min',        # Monitored metric is expected to decrease (default)\n    factor=0.1,        # Factor by which the learning rate will be reduced (default)\n    patience=2        # Number of epochs with no improvement after which learning rate will be reduced (default)\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:00:17.728961Z","iopub.execute_input":"2026-01-12T21:00:17.729891Z","iopub.status.idle":"2026-01-12T21:00:17.735788Z","shell.execute_reply.started":"2026-01-12T21:00:17.729855Z","shell.execute_reply":"2026-01-12T21:00:17.734938Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train_one_epoch(model, loader):\n    model.train()\n    total_loss, correct, total = 0.0, 0, 0\n\n    pbar = tqdm(loader, desc=\"Train\", leave=False)\n    for images, labels in pbar:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n        pbar.set_postfix(\n            loss=total_loss / (pbar.n + 1),\n            acc=correct / total\n        )\n\n    return total_loss / len(loader), correct / total\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:00:24.237854Z","iopub.execute_input":"2026-01-12T21:00:24.238576Z","iopub.status.idle":"2026-01-12T21:00:24.245037Z","shell.execute_reply.started":"2026-01-12T21:00:24.238543Z","shell.execute_reply":"2026-01-12T21:00:24.244089Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"@torch.no_grad()\ndef validate(model, loader, criterion):\n    model.eval()\n    total_loss = 0.0\n    correct, total = 0, 0\n\n    for images, labels in loader:\n        images = images.to(device, non_blocking=True)\n        labels = labels.to(device, non_blocking=True)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        total_loss += loss.item() * labels.size(0)\n        preds = outputs.argmax(dim=1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    avg_loss = total_loss / total\n    acc = correct / total\n\n    return avg_loss, acc\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:00:48.060665Z","iopub.execute_input":"2026-01-12T21:00:48.061233Z","iopub.status.idle":"2026-01-12T21:00:48.067486Z","shell.execute_reply.started":"2026-01-12T21:00:48.061189Z","shell.execute_reply":"2026-01-12T21:00:48.066569Z"}},"outputs":[],"execution_count":66},{"cell_type":"code","source":"best_test_acc = 0.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:01:25.479174Z","iopub.execute_input":"2026-01-12T21:01:25.479528Z","iopub.status.idle":"2026-01-12T21:01:25.483825Z","shell.execute_reply.started":"2026-01-12T21:01:25.479496Z","shell.execute_reply":"2026-01-12T21:01:25.483054Z"}},"outputs":[],"execution_count":67},{"cell_type":"code","source":"\nepochs = 5\nfor epoch in range(epochs):\n\n    train_loss, train_acc = train_one_epoch(model, train_loader)\n    test_loss, test_acc = validate(model, test_loader, criterion)\n\n    scheduler.step(test_loss)\n\n    # Save best model (by test accuracy)\n    if test_acc > best_test_acc:\n        best_test_acc = test_acc\n        torch.save(model.state_dict(), \"/kaggle/working/custom_resnet10.pth\")\n\n    print(\n        f\"Epoch {epoch+1:02d} | \"\n        f\"Train Loss {train_loss:.4f} | \"\n        f\"Train Acc {train_acc:.3f} | \"\n        f\"Test Loss {test_loss:.4f} | \"\n        f\"Test Acc {test_acc:.3f} | \"\n        f\"Best Test Acc {best_test_acc:.3f}\"\n    )\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:15:27.316954Z","iopub.execute_input":"2026-01-12T21:15:27.317320Z","iopub.status.idle":"2026-01-12T21:27:57.011995Z","shell.execute_reply.started":"2026-01-12T21:15:27.317289Z","shell.execute_reply":"2026-01-12T21:27:57.011245Z"}},"outputs":[{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 01 | Train Loss 1.5773 | Train Acc 0.524 | Test Loss 1.7309 | Test Acc 0.531 | Best Test Acc 0.531\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 02 | Train Loss 1.5556 | Train Acc 0.540 | Test Loss 1.7335 | Test Acc 0.509 | Best Test Acc 0.531\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 03 | Train Loss 1.5417 | Train Acc 0.548 | Test Loss 1.7262 | Test Acc 0.525 | Best Test Acc 0.531\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 04 | Train Loss 1.5286 | Train Acc 0.557 | Test Loss 1.7190 | Test Acc 0.540 | Best Test Acc 0.540\n","output_type":"stream"},{"name":"stderr","text":"                                                                              \r","output_type":"stream"},{"name":"stdout","text":"Epoch 05 | Train Loss 1.5164 | Train Acc 0.562 | Test Loss 1.7117 | Test Acc 0.541 | Best Test Acc 0.541\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"import torch\nimport torch.nn.functional as F\nfrom sklearn.metrics import classification_report\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nnum_classes = 7\n\n# Instantiate models\nmodel_r34 = ResNet34(num_classes=num_classes).to(device)\nmodel_r18 = ResNet18(num_classes=num_classes).to(device)\nmodel_r14 = ResNet14(num_classes=num_classes).to(device)\nmodel_r10 = ResNet10(num_classes=num_classes).to(device)\n\n# Load checkpoints\nmodel_r34.load_state_dict(torch.load(\"/kaggle/working/custom_resnet34.pth\", map_location=device))\nmodel_r18.load_state_dict(torch.load(\"/kaggle/working/custom_resnet18.pth\", map_location=device))\nmodel_r14.load_state_dict(torch.load(\"/kaggle/working/custom_resnet14.pth\", map_location=device))\nmodel_r10.load_state_dict(torch.load(\"/kaggle/working/custom_resnet10.pth\", map_location=device))\n\nmodels = [model_r34, model_r18, model_r14, model_r10]\n\n# Evaluation mode\nfor m in models:\n    m.eval()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:40:20.556834Z","iopub.execute_input":"2026-01-12T21:40:20.557629Z","iopub.status.idle":"2026-01-12T21:40:21.347515Z","shell.execute_reply.started":"2026-01-12T21:40:20.557599Z","shell.execute_reply":"2026-01-12T21:40:21.346884Z"}},"outputs":[],"execution_count":90},{"cell_type":"code","source":"import torch.nn.functional as F\n\n@torch.no_grad()\ndef ensemble_predict(models, dataloader):\n    all_preds = []\n    all_targets = []\n\n    correct = 0\n    total = 0\n\n    for images, labels in dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        probs_sum = None\n        for model in models:\n            logits = model(images)\n            probs = F.softmax(logits, dim=1)\n            probs_sum = probs if probs_sum is None else probs_sum + probs\n\n        avg_probs = probs_sum / len(models)\n        preds = avg_probs.argmax(dim=1)\n\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n        all_preds.append(preds.cpu())\n        all_targets.append(labels.cpu())\n\n    accuracy = correct / total\n    print(f\"Ensemble Test Accuracy: {accuracy:.4f}\")\n\n    all_preds = torch.cat(all_preds).numpy()\n    all_targets = torch.cat(all_targets).numpy()\n\n    return all_targets, all_preds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:40:23.320337Z","iopub.execute_input":"2026-01-12T21:40:23.320931Z","iopub.status.idle":"2026-01-12T21:40:23.326918Z","shell.execute_reply.started":"2026-01-12T21:40:23.320903Z","shell.execute_reply":"2026-01-12T21:40:23.326180Z"}},"outputs":[],"execution_count":91},{"cell_type":"code","source":"y_true, y_pred = ensemble_predict(models, test_loader)\n\nprint(classification_report(\n    y_true,\n    y_pred,\n    target_names=[\n        \"Angry\", \"Disgust\", \"Fear\",\n        \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"\n    ]\n))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-12T21:40:26.244202Z","iopub.execute_input":"2026-01-12T21:40:26.244680Z","iopub.status.idle":"2026-01-12T21:41:06.136977Z","shell.execute_reply.started":"2026-01-12T21:40:26.244653Z","shell.execute_reply":"2026-01-12T21:41:06.136233Z"}},"outputs":[{"name":"stdout","text":"Ensemble Test Accuracy: 0.6410\n              precision    recall  f1-score   support\n\n       Angry       0.55      0.63      0.59       958\n     Disgust       0.27      0.77      0.40       111\n        Fear       0.50      0.43      0.46      1024\n       Happy       0.90      0.80      0.85      1774\n         Sad       0.64      0.55      0.59      1233\n    Surprise       0.52      0.54      0.53      1247\n     Neutral       0.75      0.83      0.78       831\n\n    accuracy                           0.64      7178\n   macro avg       0.59      0.65      0.60      7178\nweighted avg       0.66      0.64      0.65      7178\n\n","output_type":"stream"}],"execution_count":92}]}